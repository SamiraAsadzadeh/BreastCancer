{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"U-NET.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNsCg8Sz26AfKsomC4D+rOw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Rz0E5LGLBYLP"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77063,"status":"ok","timestamp":1650256404491,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"},"user_tz":-270},"id":"HoTn4dO1gyNo","outputId":"732e08b7-eddb-4121-888e-ecbd858dbfed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==1.15.0\n","  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n","\u001b[K     |████████████████████████████████| 412.3 MB 25 kB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n","\u001b[K     |████████████████████████████████| 503 kB 50.4 MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.14.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.21.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n","Collecting keras-applications>=1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 40.2 MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.44.0)\n","Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.0.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.6)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.8.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=27b11e3e0b26912c466601eda5b35f40650832d777ea85978b86542e9afc637f\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","Successfully built gast\n","Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.8.0\n","    Uninstalling tensorboard-2.8.0:\n","      Successfully uninstalled tensorboard-2.8.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.0\n","    Uninstalling tensorflow-2.8.0:\n","      Successfully uninstalled tensorflow-2.8.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"]}],"source":["!pip install tensorflow==1.15.0\n","!pip install scikit-learn\n","!pip install keras\n","#==1.15.0"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3751,"status":"ok","timestamp":1650256408208,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"},"user_tz":-270},"id":"yZXYdTiz-2yS","outputId":"d2ffb350-fb2f-422f-bd14-9b3f969f94f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.5)\n"]}],"source":["!pip install opencv-python"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3515,"status":"ok","timestamp":1650256411686,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"},"user_tz":-270},"id":"VTiGrYCUFeIQ","outputId":"9e2d9ab2-55ba-488f-d139-7ae2df1dbf7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-plot\n","  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n","Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.1.0)\n","Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.2)\n","Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.8)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.21.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->scikit-plot) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n","Installing collected packages: scikit-plot\n","Successfully installed scikit-plot-0.3.7\n"]}],"source":["!pip install scikit-plot"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6529,"status":"ok","timestamp":1650256737707,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"},"user_tz":-270},"id":"XBUKGxtaAqLF","outputId":"0ac4c56d-6701-42ba-daf6-62bac118d308"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (4.1.1)\n"]}],"source":["!pip install torch\n","!pip install torchvision"]},{"cell_type":"code","source":["pip install Keras==2.2.4 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvgjFjQrCTH3","executionInfo":{"status":"ok","timestamp":1650257929117,"user_tz":-270,"elapsed":5055,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"}},"outputId":"d86ed467-942a-4334-e7e8-b19f8da7c805"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Keras==2.2.4\n","  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 312 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (3.13)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (1.1.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (3.1.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (1.15.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (1.21.5)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4) (1.0.8)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras==2.2.4) (1.5.2)\n","Installing collected packages: Keras\n","  Attempting uninstall: Keras\n","    Found existing installation: keras 2.8.0\n","    Uninstalling keras-2.8.0:\n","      Successfully uninstalled keras-2.8.0\n","Successfully installed Keras-2.2.4\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23125,"status":"ok","timestamp":1650256766534,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"},"user_tz":-270},"id":"m8BX-bDmiZGL","outputId":"79bc1f6b-50b5-47b4-efad-d2fb698f5131"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","'Abstract.Samira Asadzadeh.pdf'\n","'Argent Wallet'\n","'Colab Notebooks'\n","'FINAL DOCUMENT .docx'\n","'FINAL DOCUMENT .pdf'\n","'Final PEdit.pptx'\n"," form1.doc.gdoc\n"," Fusion_of_CNN_Features_and_Ensemble_Classifiers.ipynb\n","\"I am sharing '۱' with you\"\n"," IMG-1109.PNG\n"," Project\n"," Sample\n"," SAVABEGH.pdf\n","'Thesis(Summer 2019).pdf'\n"," Untitled0.ipynb\n","'zaban nosrat mobile.rar'\n"," zangkhor.mp3\n","'آدرس کیف پول.gdoc'\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","!ls 'drive/My Drive'"]},{"cell_type":"code","source":["if hasattr(tf.contrib, 'ctc'):\n","  ctc = tf.contrib.ctc  # old version\n","else:\n","  ctc = tf.nn  # New official version."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NxUs4FDhCEN5","executionInfo":{"status":"ok","timestamp":1650257844423,"user_tz":-270,"elapsed":423,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"}},"outputId":"759e02f7-4ac2-4251-92ab-da33e7f195ae"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"]}]},{"cell_type":"markdown","source":["# **Import necessary packages**"],"metadata":{"id":"6eiJCh8uB7Ft"}},{"cell_type":"code","source":["import os\n","import random\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","plt.style.use(\"ggplot\")\n","%matplotlib inline\n","\n","from tqdm import tqdm_notebook, tnrange\n","from skimage.io import imshow\n","from skimage.transform import resize\n","# from skimage.morphology import label\n","# from skimage.feature import structure_tensor\n","from sklearn.model_selection import train_test_split\n","# from PIL import Image, ImageDraw\n","# import cv2\n","\n","import tensorflow as tf\n","\n","from keras import backend as K\n","from keras.models import Model, load_model\n","from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n","from keras.layers.core import Lambda, RepeatVector, Reshape\n","from keras.layers.convolutional import Conv2D, Conv2DTranspose\n","from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n","from keras.layers.merge import concatenate, add\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"],"metadata":{"id":"K_6mEnQDB1wc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650257938381,"user_tz":-270,"elapsed":445,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"}},"outputId":"3c72b44d-61b2-49fa-e7d4-49078b1e3b91"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]}]},{"cell_type":"markdown","source":["# **Define custom functions**"],"metadata":{"id":"WCjDxoY_CAqB"}},{"cell_type":"code","source":["# Convolution block\n","def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n","    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n","    # first layer\n","    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n","              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n","    if batchnorm:\n","        x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    \n","    # second layer\n","    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n","              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n","    if batchnorm:\n","        x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    \n","    return x\n","\n","# Create u-net model\n","def get_unet(input_img, n_filters = 64, dropout = 0.1, batchnorm = True):\n","    \"\"\"Function to define the UNET Model\"\"\"\n","    \n","    # Contracting Path\n","    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","    p1 = Dropout(dropout)(p1)\n","    \n","    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n","    p2 = MaxPooling2D((2, 2))(c2)\n","    p2 = Dropout(dropout)(p2)\n","    \n","    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n","    p3 = MaxPooling2D((2, 2))(c3)\n","    p3 = Dropout(dropout)(p3)\n","    \n","    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n","    p4 = MaxPooling2D((2, 2))(c4)\n","    p4 = Dropout(dropout)(p4)\n","    \n","    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n","    \n","    # Expansive Path\n","    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n","    u6 = concatenate([u6, c4])\n","    u6 = Dropout(dropout)(u6)\n","    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n","    \n","    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n","    u7 = concatenate([u7, c3])\n","    u7 = Dropout(dropout)(u7)\n","    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n","    \n","    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n","    u8 = concatenate([u8, c2])\n","    u8 = Dropout(dropout)(u8)\n","    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n","    \n","    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n","    u9 = concatenate([u9, c1])\n","    u9 = Dropout(dropout)(u9)\n","    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n","    \n","    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n","    model = Model(inputs=[input_img], outputs=[outputs])\n","    return model\n","\n","# Compute Intersection over union (IoU), a measure of labelling accuracy\n","# NOTE: This is sometimes also called Jaccard score\n","def IoU(y_true, y_pred, smooth=1):\n","    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n","    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n","    iou = (intersection + smooth) / ( union + smooth)\n","    return iou"],"metadata":{"id":"9r1goedTCFLa","executionInfo":{"status":"ok","timestamp":1650257984911,"user_tz":-270,"elapsed":405,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1650258119632,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"},"user_tz":-270},"id":"7C8UYisdhOKk"},"outputs":[],"source":["\n","# 2. Define Train & Test Path (Images + Mask Path for Train and Test Stages)\n","#Set Image Path ست کردن مسیر تصاویر\n","TRAIN_IMAGE_PATH = '/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/Inputs_Train'\n","TRAIN_MASK_PATH = '/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/Masks_Train/onehotencoding'\n","TEST_IMAGE_PATH = '/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/Inputs_Test'\n","TEST_MASK_PATH = '/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/Masks_Test'\n","DATA_PATH = '/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/data'\n","\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1358,"status":"ok","timestamp":1650258122408,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"},"user_tz":-270},"id":"KrWtvC483RX9","outputId":"79914762-b49e-4202-c38b-3d22cac90085"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{},"execution_count":15}],"source":["# دسترسی به لیست فایلهای موجود در مسیر به صورت مرتب شده \n","#2 برای دسترسی به لیست فولدر  1# برای دسترسی به لیست فایل\n","#  os  برای دسترسی به لیست فایل ها در ماژول walk یک دستور هست به نام\n","Train_Mask_List = sorted(next(os.walk(TRAIN_MASK_PATH))[2]) \n","Train_Input_List = sorted(next(os.walk(TRAIN_IMAGE_PATH))[2]) \n","Test_Mask_List = sorted(next(os.walk(TEST_MASK_PATH))[2])\n","Train_Mask_List\n","len(Train_Mask_List)"]},{"cell_type":"markdown","source":["**APONEUROSIS TRAINING**\n","# **Set image scaling parameters, determine no. of images for training**"],"metadata":{"id":"-xVx21KiCSSQ"}},{"cell_type":"code","source":["# Images will be re-scaled\n","im_width = 224\n","im_height = 224\n","border = 5\n","\n","# list of all images in the path\n","ids = next(os.walk(\"TRAIN_IMAGE_PATH\"))[2] \n","print(\"Total no. of aponeurosis images = \", len(ids))\n","X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n","y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)"],"metadata":{"id":"m9h3ChOpCWWR","colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"status":"error","timestamp":1650258157809,"user_tz":-270,"elapsed":369,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"}},"outputId":"7db20580-afc7-45ed-8550-0774c78e9501"},"execution_count":16,"outputs":[{"output_type":"error","ename":"StopIteration","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-49786e62a427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# list of all images in the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRAIN_IMAGE_PATH\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total no. of aponeurosis images = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStopIteration\u001b[0m: "]}]},{"cell_type":"markdown","source":["# **Load images and corresponding labels (masks)**"],"metadata":{"id":"rOVbcpkOCfuc"}},{"cell_type":"code","source":["# tqdm is used to display the progress bar\n","for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n","    # Load images\n","    img = load_img(\"apo_images/\"+id_, color_mode='grayscale')\n","    x_img = img_to_array(img)\n","    x_img = resize(x_img, (512, 512, 1), mode = 'constant', preserve_range = True)\n","    # Load masks\n","    mask = img_to_array(load_img(\"apo_masks/\"+id_, color_mode='grayscale'))\n","    mask = resize(mask, (512, 512, 1), mode = 'constant', preserve_range = True)\n","    # Normalise and store images\n","    X[n] = x_img/255.0\n","    y[n] = mask/255.0"],"metadata":{"id":"m0qI48E2CbcU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Set up aponeurosis training**"],"metadata":{"id":"RDZfhKOfCqLv"}},{"cell_type":"code","source":["# Split data into training and validation\n","# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1) # i.e. 90% training / 10% test split"],"metadata":{"id":"ppEM60vWCsYz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize a random image along with the mask (not necessary, just for checking)\n","#ix = random.randint(0, len(X_train))\n","#has_mask = y_train[ix].max() > 0 # Check whether there's at least 1 aponeurosis\n","#fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 12))\n","#ax1.imshow(X_train[ix, ..., 0], cmap = 'gray', interpolation = 'bilinear')\n","# if has_mask: # if at least 1 aponeurosis is present\n","    # draw the aponeuroses on the original image\n","#     ax1.contour(y_train[ix].squeeze(), colors = 'k', linewidths = 5, levels = [0.5])\n","# ax1.set_title('Original image')\n","# ax2.imshow(y_train[ix].squeeze(), cmap = 'gray', interpolation = 'bilinear')\n","# ax2.set_title('Mask only')"],"metadata":{"id":"kaOuawf5CwjC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the aponeurosis model\n","input_img = Input((im_height, im_width, 1), name='img')\n","model_apo = get_unet(input_img, n_filters=64, dropout=0.25, batchnorm=True)\n","model_apo.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\", IoU])"],"metadata":{"id":"a6oAoSBtC0tq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show a summary of the model structure\n","model_apo.summary()"],"metadata":{"id":"XtaS9pxUC-2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.keras.utils.plot_model(model, show_shapes=True)"],"metadata":{"id":"DeV5dsKFDA9G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set some training parameters\n","callbacks = [\n","    EarlyStopping(patience=8, verbose=1),\n","    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n","    ModelCheckpoint('model-apo2-nc.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n","    CSVLogger('apo2_weights.csv', separator=',', append=False)\n","]"],"metadata":{"id":"bmN8zCYUDOfB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Train the aponeurosis model (keep batch size small!)**"],"metadata":{"id":"qfEhtaNFDURY"}},{"cell_type":"code","source":["results = model_apo.fit(X_train, y_train, batch_size=2, epochs=60, callbacks=callbacks, validation_data=(X_valid, y_valid))"],"metadata":{"id":"3qn38G57DWxN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualise the results of training\n","# Variables stored in results.history: val_loss, val_acc, val_IoU, loss, acc, IoU, lr\n","fig, ax = plt.subplots(1, 2, figsize=(20, 8))\n","ax[0].plot(resultsF.history[\"loss\"], label=\"Training loss\")\n","ax[0].plot(resultsF.history[\"val_loss\"], label=\"Validation loss\")\n","ax[0].set_title('Learning curve')\n","ax[0].plot( np.argmin(resultsF.history[\"val_loss\"]), np.min(resultsF.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n","ax[0].set_xlabel(\"Epochs\")\n","ax[0].set_ylabel(\"log_loss\")\n","ax[0].legend();\n","\n","ax[1].plot(resultsF.history[\"val_IoU\"], label=\"Training IoU\")\n","ax[1].plot(resultsF.history[\"IoU\"], label=\"Validation IoU\")\n","ax[1].set_title(\"IoU curve\")\n","ax[1].set_xlabel(\"Epochs\")\n","ax[1].set_ylabel(\"IoU score\")\n","ax[1].legend();"],"metadata":{"id":"-qR_lNmSDbKM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Evaluate on validation set (loss, acc, IoU)\n","# modelF.evaluate(X_validF, y_validF, verbose=2)"],"metadata":{"id":"G7i7FG-0Dw8g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict on training and validations sets\n","preds_trainF = modelF.predict(X_trainF, verbose=1)\n","preds_valF = modelF.predict(X_validF, verbose=1)\n","\n","# Threshold predictions (only keep predictions with a minimum level of confidence)\n","preds_train_tF = (preds_trainF > 0.5).astype(np.uint8)\n","preds_val_tF = (preds_valF > 0.5).astype(np.uint8)"],"metadata":{"id":"Xzop1Hw9DyAX"},"execution_count":null,"outputs":[]}]}