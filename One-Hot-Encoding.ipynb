{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"One-Hot-Encoding.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOEAloB2eD6W1NdJw5hk/aN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\"\"\" @author: faradars \"\"\"\n","\n","'''  Pre_Processing Codes Include:\n","    \n","    - One_Hot Encoding\n","    - Image Re_Sizing\n","    - Image Augmentation\n","    - Image Re_Color\n","    - Image Saving\n","    - Show Results\n"],"metadata":{"id":"VDM3gDQPR_10"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7446,"status":"ok","timestamp":1650254656967,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"},"user_tz":-270},"id":"XBUKGxtaAqLF","outputId":"284c6f2f-742b-4b5c-a869-de5636c62542"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n","Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (4.1.1)\n"]}],"source":["!pip install torch\n","!pip install torchvision"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4652,"status":"ok","timestamp":1650254661594,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"},"user_tz":-270},"id":"VTiGrYCUFeIQ","outputId":"2a7b3137-3aa1-4a0f-9b15-7a3833b11c02"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-plot\n","  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n","Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.1.0)\n","Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n","Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.21.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.8)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->scikit-plot) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n","Installing collected packages: scikit-plot\n","Successfully installed scikit-plot-0.3.7\n"]}],"source":["!pip install scikit-plot"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3303,"status":"ok","timestamp":1650254664872,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"},"user_tz":-270},"id":"yZXYdTiz-2yS","outputId":"825f8ffa-654d-4d94-eb68-5a3a6d9fb1c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.5)\n"]}],"source":["!pip install opencv-python"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"9VK8VqIKA1g4","executionInfo":{"status":"ok","timestamp":1650254677267,"user_tz":-270,"elapsed":12426,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"}}},"outputs":[],"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","\n","import math\n","import time\n","import os\n","import glob\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from PIL import Image\n","from sklearn.metrics import confusion_matrix\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","from sklearn.cluster import KMeans\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import cross_val_score\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torchsummary import summary\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import itertools\n","from sklearn.metrics import confusion_matrix\n","import cv2\n","from sklearn.model_selection import cross_val_score\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing import image\n","import scikitplot as skplt\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import VotingClassifier \n","from sklearn.linear_model import LogisticRegression \n","from sklearn.svm import SVC \n","from sklearn.tree import DecisionTreeClassifier \n","from sklearn.neighbors import KNeighborsClassifier\n","import matplotlib.image as mpimg\n","from google.colab.patches import cv2_imshow\n","np.set_printoptions(precision=2)\n","use_gpu = torch.cuda.is_available()\n","np.random.seed(1234)"]},{"cell_type":"code","source":["# 1. Import Required Modules\n","\n","import os\n","import sys\n","import glob\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from keras.preprocessing import image\n","from skimage.transform import resize\n","from skimage.io import imread, imshow, imsave\n","from skimage.viewer import ImageViewer\n","#from OOP import Pre_Processing_R2g\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_A-El-amSPkI","executionInfo":{"status":"ok","timestamp":1650254678545,"user_tz":-270,"elapsed":1329,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"}},"outputId":"b62326ab-6b6d-40d0-e492-d7ff25bf36b5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: Viewer requires Qt\n","  \n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168528,"status":"ok","timestamp":1650254847059,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"},"user_tz":-270},"id":"m8BX-bDmiZGL","outputId":"170b1f7d-11dc-4f2f-b03b-df052bc90822"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","'Abstract.Samira Asadzadeh.pdf'\n","'Argent Wallet'\n","'Colab Notebooks'\n","'FINAL DOCUMENT .docx'\n","'FINAL DOCUMENT .pdf'\n","'Final PEdit.pptx'\n"," form1.doc.gdoc\n"," Fusion_of_CNN_Features_and_Ensemble_Classifiers.ipynb\n","\"I am sharing '۱' with you\"\n"," IMG-1109.PNG\n"," Project\n"," Sample\n"," SAVABEGH.pdf\n","'Thesis(Summer 2019).pdf'\n"," Untitled0.ipynb\n","'zaban nosrat mobile.rar'\n"," zangkhor.mp3\n","'آدرس کیف پول.gdoc'\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","!ls 'drive/My Drive'"]},{"cell_type":"code","source":["# 2. Set Image Path\n","\n","IMAGE_PATH = '/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/inpouts/'\n","IMAGE_MASK_PATH = '/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/mask/'\n"],"metadata":{"id":"qHrYs3uOSQUj","executionInfo":{"status":"ok","timestamp":1650254938530,"user_tz":-270,"elapsed":542,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 3. Get Images and Set Some Parameters, One_Hot Encoding Technique\n","\n","IMG_HEIGHT = 720\n","IMG_WIDTH = 1128\n","IMG_CHANNELS = 3"],"metadata":{"id":"klG6NB7ESWPk","executionInfo":{"status":"ok","timestamp":1650255556493,"user_tz":-270,"elapsed":545,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#image4 = mpimg.imread('/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/mask/1_268_10_3.jpg')\n","IMG_Dataset = next(os.walk(IMAGE_PATH))[2] \n","\n","Inputs = np.zeros((len(IMG_Dataset), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n","                  dtype = np.uint8)\n","\n","print('Loading Images & Masks, Please Wait')\n","sys.stdout.flush()\n","for n, f in tqdm(enumerate(IMG_Dataset), total = len(IMG_Dataset)): #n شماره فال و f نام فایل  ذخیره میگردد\n","    Imagesmask = imread (IMAGE_MASK_PATH + f.replace('0.', ''))[:,:,:IMG_CHANNELS]\n","    Inputs[n] = Imagesmask\n","\n","    filename_w_ext = os.path.basename(f)\n","    filename, file_extension = os.path.splitext(filename_w_ext)\n","    \n","    #img = mpimg.imread('/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/mask/1_268_10_3.jpg')\n","    plt.imshow(Inputs[n]), plt.title('Orginnal Masks')\n","    plt.show()\n","    median = cv2.medianBlur(Inputs[n],5)\n","    #تبدیل فضای رنگ bgr to hsv\n","    hsv = cv2.cvtColor(median,cv2.COLOR_BGR2HSV )\n","    plt.imshow(hsv), plt.title('Hsv Masks')\n","    plt.show() \n","    lower_blue = np.array([110,50,50])\n","    upper_blue = np.array([120,255,255])\n"," \n","    lower_green = np.array([50,50,50])\n","    upper_green = np.array([60,255,255])\n"," \n","    lower_red = np.array([0,50,50])\n","    upper_red = np.array([0,255,255])\n","    #آستانه گیری(cv2.inRange())\n","    maskb = cv2.inRange(hsv, lower_blue, upper_blue)\n","    maskg = cv2.inRange(hsv, lower_green, upper_green)\n","    maskr = cv2.inRange(hsv, lower_red, upper_red)\n","    output_path = '/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/Masks_Train'\n","    cv2.imwrite(os.path.join(output_path, filename +'.jpg' ),maskb)\n","    # and تصویر اصلی با ماسک\n","    #میشود (cv2.bitwise_and())\n","    resb = cv2.bitwise_and(Inputs[n],Inputs[n], mask= maskb)\n","    resg = cv2.bitwise_and(Inputs[n],Inputs[n], mask= maskg)\n","    resr = cv2.bitwise_and(Inputs[n],Inputs[n], mask= maskr)\n","    plt.figure(figsize=(14, 14))\n","    plt.subplot(231), plt.imshow(maskb, cmap='gray')\n","    plt.title('b'), plt.xticks([]), plt.yticks([])\n","    plt.subplot(232), plt.imshow(maskg)\n","    plt.title('g'), plt.xticks([]), plt.yticks([])\n","    plt.subplot(233), plt.imshow(maskr)\n","    plt.title('r'), plt.xticks([]), plt.yticks([])\n","    plt.show()\n","    plt.figure(figsize=(14, 14)) \n","    plt.subplot(231), plt.imshow(resb, cmap='gray')\n","    plt.title('resb'), plt.xticks([]), plt.yticks([])\n","    plt.subplot(232), plt.imshow(resg)\n","    plt.title('resg'), plt.xticks([]), plt.yticks([])\n","    plt.subplot(233), plt.imshow(resr)\n","    plt.title('resr'), plt.xticks([]), plt.yticks([])\n","    plt.show()\n","\n","cv2.waitKey()\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1TA-D1C683EBukUVfJPZvuYxaeEKAyk4T"},"id":"FJlD2NKq2xoY","executionInfo":{"status":"ok","timestamp":1650255799747,"user_tz":-270,"elapsed":58317,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"}},"outputId":"de650fdc-0ffe-4768-99d2-aafee0df25da"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["Ground_Truth_PATH = '/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/Masks_Train/'\n","IMG_Dataset = next(os.walk(Ground_Truth_PATH))[2] \n","\n","#Inputs = np.zeros((len(IMG_Dataset), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n","                  #dtype = np.uint8)\n","Ground_Truth = np.zeros((len(IMG_Dataset), IMG_HEIGHT, IMG_WIDTH, 2),\n","                  dtype = np.bool)\n","print('Loading Images & Masks, Please Wait')\n","sys.stdout.flush()\n","\n","for n, g in tqdm(enumerate(IMG_Dataset), total = len(IMG_Dataset)): #n شماره فال و f نام فایل  ذخیره میگردد\n","    Images = imread (Ground_Truth_PATH + g)\n","    #Inputs[n] = Images\n","    filename_w_ext = os.path.basename(g)\n","    filename1, file_extension = os.path.splitext(filename_w_ext)\n","    plt.imshow(Images ), plt.title('Orginnal Masks')\n","    plt.show()\n","    \n","    Masks = imread(Ground_Truth_PATH + g)              \n","    Masks = np.squeeze(Masks).astype(np.bool)     \n","    Ground_Truth[n, :, :, 0] = ~Masks\n","    Ground_Truth[n, :, :, 1] = Masks\n","    Masks = np.array(255*np.squeeze(Masks), np.uint8)\n","    #Masks =  np.array(Masks).astype(np.float32)\n","    plt.imshow(Masks, cmap='gray'), plt.title('Ground_Truth')\n","    plt.show()\n","    Masks = cv2.resize(Masks  , (224, 224))\n","    output_path = '/content/drive/MyDrive/Project/BreastCancer/Dataset/Dataset/Masks_Train/onehotencoding'\n","    cv2.imwrite(os.path.join(output_path, filename1 +'.jpg' ), Masks)\n","print('Loading Images and Masks Completed Successfully!')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1KdDfUcPFXz15RRZb6VXIDlAiYWeA6UF1"},"id":"ZWiuM1TEStmj","executionInfo":{"status":"ok","timestamp":1650255879993,"user_tz":-270,"elapsed":25800,"user":{"displayName":"samira asadzadeh","userId":"04082349778136253686"}},"outputId":"124d95e2-061c-4c2b-f790-c7dd89317796"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9stPh0AxR5pq"},"outputs":[],"source":["# 4. Define Functions: Re_Size, Augmentation, Re_Color, Im_Saving\n","# 4.1. Function_1: Pre_Process_Re_Size():\n","\n","#IMG_HEIGHT_RESIZED = 255\n","#IMG_WIDTH_RESIZED = 255\n","#IMG_CHANNELS_RESIZED = 3\n","#\n","#def Pre_Process_Re_Size(imgs):\n","#    \n","#    img_p = np.zeros((imgs.shape[0], IMG_HEIGHT_RESIZED, IMG_WIDTH_RESIZED\n","#                      , IMG_CHANNELS_RESIZED), dtype = np.uint8)\n","#    \n","#    for i in range(imgs.shape[0]):\n","#        \n","#       img_p[i] = resize(imgs[i], (IMG_HEIGHT_RESIZED, IMG_WIDTH_RESIZED,\n","#               IMG_CHANNELS_RESIZED), preserve_range=True)\n","#       \n","#    return img_p\n","#\n","#''' ------------------------------------------------------- '''\n","#\n","## 4.2. Function_2: Pre_Process_Augmentation():\n","#\n","#IMAGE_INITIAL_PATH = '/home/faradars/Desktop/Data/Augmentation/' \n","#IMAGE_AUGMENTATED_PATH = '/home/faradars/Desktop/Data/Rotated/' \n","#\n","#Data_Gen = image.ImageDataGenerator(rotation_range=30)\n","#IMG_AUG = Data_Gen.flow_from_directory(IMAGE_INITIAL_PATH, batch_size=1\n","#                                       , save_to_dir=IMAGE_AUGMENTATED_PATH,\n","#                                       save_prefix='Aug', target_size=(768,896))\n","#\n","#for i in range(9):\n","#    IMG_AUG.next()\n","#    \n","#def Pre_Process_Augmentation(Path_Images):\n","#    \n","#    Images_List = glob.glob(Path_Images)\n","#    Figure = plt.figure()\n","#    \n","#    for i in range (9):\n","#        Images_A = Image.open(Images_List[i])\n","#        Sub_Image_Show = Figure.add_subplot(331 + i)\n","#        Sub_Image_Show.imshow(Images_A)\n","#    plt.show()\n","#    return Figure\n","#    \n","#Image_Original = Pre_Process_Augmentation(IMAGE_INITIAL_PATH + 'input/*')\n","#Image_Original.savefig(IMAGE_AUGMENTATED_PATH + '/Original.png', dpi = 200,\n","#                       papertype = 'a5')\n","#\n","#Image_Augmentation = Pre_Process_Augmentation(IMAGE_AUGMENTATED_PATH + '/*')\n","#Image_Augmentation.savefig(IMAGE_AUGMENTATED_PATH + '/Rotated.png', dpi = 200,\n","#                       papertype = 'a5') \n","#\n","#\n","#Image_Resize = Pre_Process_Re_Size(Inputs)\n","#\n","## 5. Show Results\n","#\n","#ix = random.randint(0, len(Inputs))\n","#\n","#img = Inputs[ix]\n","#mask = Ground_Truth [ix]\n","#resized = Image_Resize [ix]\n","#gray = Gray_Scale[ix]\n","#\n","#print('Input Image')\n","#imshow(img)\n","#plt.show()\n","#\n","#print('Mask')\n","#imshow(mask[:,:,1])\n","#plt.show()\n","#\n","#print('Resized Image')\n","#imshow(resized)\n","#plt.show()\n","#\n","#print('GrayScale Image')\n","#imshow(gray)\n","#plt.show()\n","#\n","#\n","#image_viewer = ImageViewer(gray)\n","#image_viewer.show()"]},{"cell_type":"code","source":["# 4.3. Function_3: Pre_Process_Re_Color():\n","\n","Object_Pre_Preocessing = Pre_Processing_R2g(Inputs)\n","Gray_Scale = Pre_Processing_R2g.R_2_G(Object_Pre_Preocessing)\n"],"metadata":{"id":"53KPk1_2Smg7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"1gWLPEfDS7oM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4.4. Function_4: Pre_Process_Im_Saving():\n","\n","New = 'D:/Python/Breast/'\n","\n","def Pre_Process_Im_Saving(Path_Images, Path_Output, Tensor):\n","    \n","    for i, filename in enumerate(os.listdir(Path_Images)):\n","        \n","        imsave(fname='{}{}'.format(Path_Output, filename),\n","               arr=Tensor[i])\n","        \n","        print('{}: {}'.format(i, filename))\n","    \n","Pre_Process_Im_Saving(IMAGE_PATH, New, Gray_Scale)"],"metadata":{"id":"33YMbHcsS5a-"},"execution_count":null,"outputs":[]}]}